---
title: "Theory"
output:
  pdf_document: default
---

Pooled or bulk RNA-seq measurements represent averaged transcriptional states of potentially many transcriptionally distinct cell-types at differing proportions. In order to estimate the proportions of these different cell-types, many computational deconvolution approaches have been developed. These deconvolution approaches have generally relied on the existence of a 'pure' cell-type reference, often generated from an external single-cell RNA-seq dataset. 

The general intuition is that given the transcriptional profiles of cell-type A `x1` and cell-type B `x2`, then if bulk RNA-seq measurement `y` that represent a mix of cell-type A and cell-type B can be represented as `y = alpha * x1 + beta * x2` where `alpha` and `beta` can be solved. We can train a supervised machine learning classifier such as an `svm` classifier based on a set of simulated `y`s where `alpha` and `beta` are known. This is the basis of CIBERSORT and other similar deconvolution methods. 

A simple simulation is shown below:

```{r, theory1}
## baseline expression
set.seed(0)
base = abs(round(rnorm(10, 10)))
names(base) <- paste0('gene', 1:10)
head(base)

## cell-type A upregulates genes 1 to 5
x1 = base
x1[1:5] = base[1:5] + 10

## cell-type B upregulates genes 6 to 10
x2 = base
x2[6:10] = base[6:10] + 10

## visualize transcriptional distinctness
heatmap(rbind(x1, x2))

## train classifier to predict proportions of cell-type A
## given a mixture of cell-type A and cell-type B
train.data <- do.call(rbind, lapply(seq(1,100, by=5), function(i) {
  ground.truth <- c(i, 100-i)
  names(ground.truth) <- c('ctA', 'ctB')
  y = ground.truth[1]*x1 + ground.truth[2]*x2
  c(y, ground.truth)
}))
rownames(train.data) <- paste0('sim', 1:nrow(train.data))
head(train.data)

## remove truth from training
train.data.sub <- as.data.frame(train.data[, names(x1)])
library(e1071)
model <- e1071::svm(train.data.sub, train.data[,'ctA'])
print(model)

# test with train data
pred <- predict(model, train.data.sub)
plot(pred, train.data[, 'ctA'])
cor(pred, train.data[, 'ctA'])

## now create real test
ground.truth <- c(30, 70)
y = ground.truth[1]*x1 + ground.truth[2]*x2
## hack to fix error
## https://stackoverflow.com/questions/24829674/r-random-forest-error-type-of-predictors-in-new-data-do-not-match/38097360#38097360
ytest <- rbind(y, train.data.sub)
y <- ytest[1,]
print(y)

pred <- predict(model, y)
print(pred)
## pretty close to 30 as expected
```

In ST data, each ST spot represents the averaged transcriptional state of 100s of cells that may represent many transcriptionally distinct cell-types at differing proportions. However, unlike in bulk RNA-seq data where we only have 1 pooled measurement, in ST data, we have 100s of spots, each representing a different mixture of the same set of cell-types within the tissue. We should be able to take advantage of this natural variation to deconvolve expression without an external single cell reference using unsupervised machine learning approaches such as latent direchlet allocation. 

Latent direchlet allocation (LDA) is a machine learning approach often used in topic modeling. Given a set of articles, each with many many words, LDA will learn the underlying set of topics, which are defined by different words, and assess the proportional representation of each topic in each article. An analogy can be made with ST data where given a set of spots, each with many many genes, LDA can learn the underlying set of cell types, which are defined by expression of different genes, and assess the proportional representation of each cell-type in each spot. 

Consider if `train.data.sub` was the transcriptional profiles of each spot. Note, in LDA, we do have to define the number of topics (or cell-types). Here, we already know that there are two cell-types. However, we do not have to provide any ground truth cell-type proportion labels. 

```{r, theory2}
library(topicmodels)
library(slam)
library(Matrix)
K = 2
ap_lda <- topicmodels::LDA(slam::as.simple_triplet_matrix(as.matrix(train.data.sub)), 
                           k=K, control = list(seed = 0))
ap_lda

## association of each gene with each cell-type
library(tidytext)
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_topics.mat <- t(cast_sparse(ap_topics, topic, term, beta))
dim(ap_topics.mat)
heatmap(as.matrix(ap_topics.mat), scale='row', Rowv=NA, Colv=NA)
```
In this case, LDA correctly identifies two cell-types, where cell-type 1 is marked by upregulation of genes 6 to 10 (our real cell-type B), and cell-type 2 is marked by upregulation of genes 1 to 5 (our real cell-type A). Likewise, we can compare the learned proportional representation to our real simulated presentation. 

```{r, theory3}
## proportional representation of each topic in each document
## or each cell-type in each spot
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents

ap_documents.mat <- cast_sparse(ap_documents, document, topic, gamma)
dim(ap_documents.mat)
head(ap_documents.mat)

plot(ap_documents.mat[,1], train.data[, 'ctB'])
cor(ap_documents.mat[,1], train.data[, 'ctB'])
plot(ap_documents.mat[,2], train.data[, 'ctA'])
cor(ap_documents.mat[,2], train.data[, 'ctA'])
```

# Questions
1. Can we create a more realistic simulation using single-cell RNA-seq data? (test.R can help you get started  
2. What happens if we choose a wrong K? Can we detect that the chosen K is wrong?  
3. Should we use all words (genes) or only train on words that are known to be variable across topics (genes that are overdispersed across cell-types)?  
4. This approach relies on variability of cell-type proportions in the training data. What happens if there is little variability? How will we know if there is enough variability in our data?  
